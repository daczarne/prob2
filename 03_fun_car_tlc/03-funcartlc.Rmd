---
title: "Capítulo 3 - Funciones características y TLC"
author: "Daniel Czarnievicz"
date: "2019"
output: pdf_document
header-includes:
   - \everymath{\displaystyle}
   - \usepackage[spanish]{babel}
   - \usepackage{xcolor}
   - \usepackage[makeroom]{cancel}
   - \DeclareMathOperator*{\plim}{plim}
   - \usepackage{mathrsfs}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \newcommand{\equalexpl}[1]{\underset{\substack{\uparrow\\\\\mathrlap{\text{\hspace{-2em}#1}}}}{\approx}}
   - \DeclareMathOperator{\E}{\mathbf{E}}
   - \DeclareMathOperator{\V}{\mathbf{V}}
geometry: margin=1in
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

- Denotaremos como $\mathbb{C}$ al conjunto de los números complejos.  
- **Módulo**: si $z = a + ib \in \mathbb{C} \Rightarrow |z| = \sqrt{a^2 + b^2}$.  
- **Conjugado**: si $z = a + ib \in \mathbb{C} \Rightarrow \bar{z} = a - ib$.  
- **Exponencial compleja**: $e^z = e^{a + ib} = e^a \, e^{ib} = e^a \big[ \cos(b) + i \sin(b) \big]$.

# Función Característica

#### Definición 3.1: Función característica

Dado $(\Omega, \, \mathcal{A}, \, P)$ un espacio de probabilidad y $X : \Omega \rightarrow \mathbb{R}$ una variable aleatoria, definimos la función característica de $X$ como:
$$\varphi_X : \mathbb{R} \rightarrow \mathbb{C} \, / \, \varphi_X(t) = \E \big( e^{itX} \big)$$

#### Observación 3.2

Dado que $e^{itX} = \cos(tX) + i \sin(tX)$ se tiene que:
$$\varphi_X(t) = \int\limits_{-\infty}^{+\infty} e^{itx} dF_X(x) = \E \big[ \cos(tX) \big] + i \, \E \big[ \sin(tX) \big]$$
como $|e^{itX}| = 1$ para todo $t$, $\exists \varphi(t) < \infty$ para todo $t$.

#### Proposición 3.3: propiedades de la función característica

1. $|\varphi_X(t)| \leq 1$ para todo $t \in \mathbb{R}$

*Dem*: $|\varphi_X(t)| = \Big| \E \big(e^{itX} \big) \Big| \leq \E \big|e^{itX} \big| = \E (1) = 1$ dado que $g(z) = |z|$ es una función convexa.

***

2. $\varphi_X(0) = 1$

*Dem*: $|\varphi_X(0)| = \Big| \E \big(e^{it(0)} \big) \Big| = \E \big|e^{0} \big| = \E (1) = 1$.

3. $\varphi_{aX+b}(t) = e^{itb} \, \varphi_X(at)$

*Dem*: 
$$\varphi_{aX+b}(t) = \E \left( \exp\big\{ it(aX + b) \big\} \right) = \E \left( \exp\big\{ itaX + itb \big\} \right) = \E \left( \exp\big\{ itaX \big\} \exp\big\{ itb \big\} \right) =$$
$$= e^{itb} \E \Big( e^{itaX} \Big) = e^{itb} \varphi_X(ta)$$

***

4. Si $X$ e $Y$ son independientes, entonces $\varphi_{X + Y}(t) = \varphi_X (t) \, \varphi_Y (t)$ para todo $t \in \mathbb{R}$

*Dem*: 
$$\varphi_{X + Y}(t) = \E \Big[ e^{it(X+Y)} \Big] = \E \Big[ e^{itX + itY} \Big] = \E \Big[ e^{itX} e^{itY} \Big] = \E \big[ e^{itX} \big] \E \big[ e^{itY} \big] = \varphi_X(t) \, \varphi_Y(t)$$

***

5. $\varphi_X(t) = \overline{ \varphi_X (-t) }$

*Dem*: recordemos que:

- $\sin(x)$ es impar, por lo tanto, $\sin(x) = - \sin(-x)$, y $\int\limits_{\mathbb{R}} \sin(x) dx = 0$. 
- $\cos(x)$ es par, por lo tanto, $\cos(x) = \cos(-x)$, y $\int\limits_{\mathbb{R}} \cos(x) dx = 2 \int\limits_0^{+\infty} \cos(x) dx$. 

$$\overline{ \varphi_X (-t) } = \overline{ \E \big[ \cos(-tX) + i \sin(-tX) \big] } = \overline{ \E \big[ \cos(tX) - i \sin(-tX) \big] } = \E \big[ \cos(tX) + i \sin(tX) \big] = \varphi_x(t)$$

***

#### Proposición 3.4: función característica de una variable aleatoria con distribución Normal

Si $X \sim \text{N}(\mu, \, \sigma^2)$, entonces $\varphi_X(t) = \exp\left\{ i t \mu - \frac{1}{2} (\sigma t)^2 \right\}$

*Dem*: primero hallamos la función característica de una distribución $\text{Normal}(0, 1)$, y luego utilizamos la propiedad 3 para hallar la de una $\text{Normal}(\mu, \sigma^2)$.

$$\varphi_X(t) = \E \big[ e^{itX} \big] = \int\limits_{-\infty}^{+\infty} e^{itx} \, \phi_X(x) dx = \int\limits_{-\infty}^{+\infty} e^{itx} \, \frac{1}{ \sqrt{2 \pi} } e^{-x^2 / 2} dx$$

$$\frac{ \partial }{ \partial t } \varphi_X (t) = \frac{ \partial }{\partial t} \int\limits_{-\infty}^{+\infty} e^{itx} \frac{1}{ \sqrt{2 \pi} } \, e^{- x^2 / 2} dx = \int\limits_{-\infty}^{+\infty} \left( \frac{ \partial }{\partial t} \, e^{itx} \right) \frac{1}{ \sqrt{2 \pi} } \, e^{- x^2 / 2} dx =$$
$$= \int\limits_{-\infty}^{+\infty} i x \, e^{itx} \frac{1}{ \sqrt{2 \pi} } \, e^{- x^2 / 2} dx = -\frac{ i }{ \sqrt{2 \pi} } \int\limits_{-\infty}^{+\infty} e^{itx} \, (-x) \, e^{- x^2 / 2} dx$$

Podemos luego entonces aplicar integración por partes donde $g(x) = e^{itx} \Rightarrow g'(x) = it \, e^{itx}$, y $f'(x) = (-x) \, e^{- x^2 / 2} \Rightarrow f(x) = e^{-x^2 / 2}$ y obtenemos que:

$$\frac{ \partial }{ \partial t } \varphi_X (t) = i \left[ \frac{ \big( -e^{-x^2 / 2} \big) \big( e^{itx} \big) }{ \sqrt{2 \pi} } \, \Bigg|_{-\infty}^{+\infty} - \int\limits_{-\infty}^{+\infty} \left( \frac{ -e^{-x^2 / 2} }{ \sqrt{2 \pi} } \right) e^{itx} (it) \, dx \right]$$
Donde el primer sumando es cero dado que $-e^{-x^2 / 2}$ tiende a cero en los límites propuestos, mientras que $e^{itx}$ está acotada, dado que podemos escribirla como una función de senos y cosenos, los cuales están acotados. Por lo tanto, obtenemos que:

$$\frac{ \partial }{ \partial t } \varphi_X (t) = - i \int\limits_{-\infty}^{+\infty} \left( \frac{ -e^{-x^2 / 2} }{ \sqrt{2 \pi} } \right) e^{itx} (it) \, dx = - t \int\limits_{-\infty}^{+\infty} \left( \frac{ -e^{-x^2 / 2} }{ \sqrt{2 \pi} } \right) e^{itx} dx = - t \, \varphi_X(t)$$

Por lo tanto, hallamos que $\varphi'_X(t) = - t \varphi_X(t)$. Esto equivale a resolver la ecuación diferencial lineal de primer orden $\varphi'_X(t) + t \varphi_X(t) = 0$. POr lo tanto, tenemos que:

$$\left. \begin{array}{l}
\varphi_X(t) = c \, e^{-t^2 / 2} \\
\varphi_X(0) = 1 \Rightarrow c = 1
\end{array} \right\} \Rightarrow \varphi_X(t) = e^{-t^2 / 2}$$

Aplicando ahora la propiedad 3, obtenemos que:
$$\varphi_{\sigma X + \mu} (t) = e^{it \mu} e^{-(\sigma t)^2 / 2} = \exp\left\{ it \mu - \frac{ (\sigma t)^2 }{2} \right\}$$

#### Proposición 3.5

$\varphi_X(t)$ es uniformemente continua.

<!--
*Dem*: observemos que:

$$\varphi_X(t) - \varphi_X(s) = \E \big( e^{itX} \big) - \E \big( e^{isX} \big) $$
-->

#### Proposición 3.6

Si $\E |X|^n < \infty$ para algún $n \geq 1$ entonces:

- Existen las derivadas de $\varphi_X$ de orden $1, \ldots, n$

- $\varphi_X^{(r)}(t) = \int\limits_{\mathbb{R}} (ix)^r e^{itx} dF(x) = i^r \, \E(X^r \, e^{itX} )$

- $i^r \, \E(X^r) = \varphi_X^{(r)}(0)$ 

- $\varphi_X(t) = \sum\limits_{r = 0}^{n} \frac{(it)^r}{r!} \E (X^r) + \frac{(it)^n}{n!} \varepsilon_n(t)$ donde $|\varepsilon_n(t)| \leq 3 \E(|X|^n)$ y $\varepsilon_n(t) \overset{t}{\rightarrow} 0$

#### Teorema 3.7: Fórmula de inversión

sea $F = F(x)$ una función de distribución y $\varphi(t) = \int\limits_{\mathbb{R}} e^{itx} dF(x)$ su función característica, entonces:

- Para todo par $a < b$ de puntos de continuidad de $F$ se cumple que:
$$F(b) - F(a) = \lim\limits_{c \rightarrow +\infty} \frac{1}{2 \pi} \int\limits_{-c}^{c} \frac{ e^{-ita} - e^{-itb} }{it} \varphi(t) dt$$

- Si además, $\int\limits_{\mathbb{R}} |\varphi (t)| dt < \infty$ entonces, $F$ tiene densidad $f$ dada por:
$$f(x) = \frac{1}{2 \pi} \int\limits_{\mathbb{R}} e^{-tx} \varphi(t) dt$$

#### Corolario 3.8

Si $F$ y $G$ son distribuciones tales que $\int\limits_{\mathbb{R}} e^{itx} dF(x) = \int\limits_{\mathbb{R}} e^{itx} dG(x)$ para todo $t \in \mathbb{R} \Rightarrow F = G$. 

#### Definicion 3.9: Función característica en general

Dado $(\Omega, \, \mathcal{A}, \, P)$ un espacio de probabilidad y $X : \Omega \rightarrow H$ siendo $H$ un espacio vectorial con un producto interno $\langle \cdot \, , \,  \cdot \rangle$ definimos la función característica como:
$$\varphi_X : H \rightarrow \mathbb{C} / \varphi_X (t) = \E \big( e^{i \langle t, X \rangle } \big)$$

#### Teorema 3.10

Una condición necesaria y suficiente para que las componentes del vector $\xi = (\xi_1, \ldots, \xi_d)'$ sean independientes es que la función característica de $\xi$ sea el producto de las funciones características de las componentes $\xi_i$.
$$\E \left[ \exp\big\{ i ( t_1 \xi_1 + \ldots + t_d \xi_d ) \big\} \right] = \prod\limits_{k = 1}^{d} \E \left[ \exp\big\{ i t_k \xi_k \big\} \right] $$

#### Teorema 3.11

Dada $\{X_n\}_{n \in \mathbb{N}}$ una sucesión de variables aleatorias definidas en $(\Omega_n, \, \mathcal{A}_n, \, P_n)$ y una variable aleatoria $X$ definida en $(\Omega, \, \mathcal{A}, \, P)$, son equivalentes:

1. $X_n \overset{d}{\rightarrow} X$

2. $\varphi_{X_n} (t) \overset{n}{\rightarrow} \varphi_X(t)$ para todo $t \in \mathbb{R}$


# Teorema del Límite Central

## Variables iid

#### Teorema 3.12: Teorema de Levy

Sean $X_1; \, \ldots; \, X_n$ iid con función de distribución $F$ tal que $\E(X_1) = \mu$ y $\V(X_1) = \sigma^2$. Si denotamos a $S_n = \sum\limits_{i = 1}^{n} X_i$, entonces:
$$\frac{ S_n - n \, \mu }{ \sigma \sqrt{n} } \overset{d}{\rightarrow} Z \sim \text{N}(0, 1)$$

*Dem*: para facilitar notación, llamemos $Z_n = \frac{ S_n - n \, \mu }{ \sigma \sqrt{n} }$. Sean las variables $Y_i$ tales que:

- $Y_i = \frac{ X_i - \mu }{ \sigma }$.

- $\E(Y_i) = \E \left[ \frac{ X_i - \mu }{ \sigma } \right] = \frac{1}{\sigma} \left[ \E(X_i) - \mu \right] = 0$

- $\V(Y_i) = \V \left[ \frac{ X_i - \mu }{ \sigma } \right] = \frac{1}{\sigma^2} \V(X_i) = 1$

- $Z_n = \frac{ S_n - n \, \mu }{ \sigma \sqrt{n} } = \frac{ \sum\limits_{i = 1}^{n} X_i - n \, \mu }{ \sigma \sqrt{n} } = \frac{ \sum\limits_{i = 1}^{n} ( X_i - \mu ) }{ \sigma \sqrt{n} } = \frac{1}{\sqrt{n}} \sum\limits_{i = 1}^{n} \left( \frac{ X_i - \mu }{ \sigma } \right) = \frac{1}{\sqrt{n}} \sum\limits_{i = 1}^{n} Y_i$

Luego entonces,

$$\begin{array}{rclcl}
\varphi_{Z_n}(t) & = & \E \big( e^{itZ_n} \big) & & \\ \\
   & = & \E \left( \exp\left\{ it \frac{1}{\sqrt{n}} \sum\limits_{i = 1}^{n} Y_i \right\} \right) & & \\ \\
   & = & \E \left( \exp\left\{ it \frac{1}{\sqrt{n}} Y_1 \right\} \right) \ldots \E \left( \exp\left\{ it \frac{1}{\sqrt{n}} Y_n \right\} \right) & & \text{por independencia} \\ \\
   & = & \varphi_{Y_1} \left( ^t/\!_{\sqrt{n}} \right) \ldots \varphi_{Y_n} \left( ^t/\!_{\sqrt{n}} \right) & & \text{por definición de función característica} \\ \\
   & = & \left[ \varphi_{Y_1} \left( ^t/\!_{\sqrt{n}} \right) \right]^n & & \text{por igual distribución}
\end{array}$$

Procedemos desarrollando el polinomio de Taylor de segundo orden (dado que sabemos que tiene derivada segunda por tener segundo momento centrado finito) en torno a $t = 0$, por lo que obtenemos que:
$$\left[ \varphi_{Y_1} \left( ^t/\!_{\sqrt{n}} \right) \right]^n = \left[ \varphi_{Y_1} (0) + \varphi'_{Y_1} (0) \frac{^t/\!_{\sqrt{n}} }{1!} + \varphi''_{Y_1} (0) \frac{ (^t/\!_{\sqrt{n}} )^2 }{ 2! } + \varepsilon_2 \left( \frac{t_1}{ \sqrt{n} } \right) \frac{ (^t/\!_{\sqrt{n}})^2 }{ 2! } \right]^n \,\,\,\,\,\,\,\, \text{con } 0 \leq t_1 \leq t$$

Luego $\varphi_{Y_1} (0) = 1$ por prop 3.3/2. Por otro lado, siguiendo la prop 3.6, obtenmos que $\varphi_{Y_1}'(0) = 0$ dado que $Y_1$ es una variable aleatoria centrada en 0, mientras que $\varphi''_{Y_1} (0) = -1$ dado que $\V(Y_1) = 1$. Por lo tanto,
$$\left[ \varphi_{Y_1} \left( ^t/\!_{\sqrt{n}} \right) \right]^n = \left[ 1 - \frac{ t^2 }{ 2 n } + \frac{ t^2 }{ 2n } \, \varepsilon_2 \left( \frac{t_1}{ \sqrt{n} } \right) \right]^n$$

Si tomamos el límite cuando $n \rightarrow +\infty$ hallamos que:
$$\lim\limits_{n \rightarrow +\infty} \varphi_{Z_n}(t) = \lim\limits_{n \rightarrow +\infty} \left[ \varphi_{Y_1} \left( ^t/\!_{\sqrt{n}} \right) \right]^n = \lim\limits_{n \rightarrow +\infty} \left[ 1 - \frac{ t^2 }{ 2 n } + \frac{ t^2 }{ 2n } \, \varepsilon_2 \left( \frac{t_1}{ \sqrt{n} } \right) \right]^n = e^{ -t^2 /2 } = \varphi_Z(t)$$

## Arreglos triangulares

