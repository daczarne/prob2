---
title: "Práctico 6"
author: "Daniel Czarnievicz"
date: "2019"
output: pdf_document
header-includes:
   - \everymath{\displaystyle}
   - \usepackage[spanish]{babel}
   - \usepackage{xcolor}
   - \usepackage[makeroom]{cancel}
   - \DeclareMathOperator*{\plim}{plim}
   - \usepackage{mathrsfs}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \newcommand{\equalexpl}[1]{\underset{\substack{\uparrow\\\\\mathrlap{\text{\hspace{-2em}#1}}}}{\approx}}
   - \DeclareMathOperator{\E}{\mathbf{E}}
   - \DeclareMathOperator{\V}{\mathbf{V}}
geometry: margin=1in
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejercicio 1

Sean las variables aleatorias $A_i =$ "sale 6 en la $i$-ésima tirada", y $A = \sum\limits_{i = 1}^{n} A_i =$ "cantidad de veces que sale 6". Entonces $A_i \sim \text{Ber}(1/6)$, mientras que $A \sim \text{Bin}(180, \, 1/6)$. Luego entonces:

$$\Pr ( \text{``sale 6 menos de 25 veces''} ) = \Pr ( A \leq 24 ) = \Pr \left( \frac{ \sum\limits_{i = 1}^{180} A_i - np }{ \sigma \sqrt{n} } \leq \frac{ 24 - np }{ \sigma \sqrt{n} } \right) =$$
$$= \Pr \left( \frac{ \sum\limits_{i = 1}^{180} A_i - 180 \, (1/6) }{ \sqrt{ (1/6) (5/6) } \, \sqrt{180} } \leq \frac{ 24 - 180 \, (1/6) }{ \sqrt{ (1/6) (5/6) } \, \sqrt{180} } \right) = \Pr \left( Z \leq \frac{ 24 - 30 }{ 30 \sqrt{5} } \right)$$

```{r, comment=""}
n <- 180
p <- 1 / 6
mu <- (n * p)
sigma <- sqrt(p * (1 - p))
x <- 24
pnorm((x - mu) / (sigma * sqrt(n)), mean = 0, sd = 1)
pbinom(x, size = n, prob = p)
sum(dbinom(1:x, size = n, prob = p))
```

\newpage

# Ejercicio 2: LDGN de Khinchin

Probar que si $\{X_n\}_{n \geq 1}$ es una sucesión de variables aleatorias iid con $\E(X_1) = \mu$, entonces $\bar{X}_n \overset{p}{\rightarrow} \mu$.

*Dem*: por el teorema de Slutsky sabemos que si una sucesión de variables aleatorias converge en distribución a una constante, entonces también converge en probabilidad a dicha constante. A su vez, por el teorema 3.11 sabemos que la convergencia de funciones características equivale a la convergencia en distribución. Por lo tanto, debemos obtener las funciones características de $\{X_n\}_{n \geq 1}$ y de $\bar{X}_n$, y verificar que se cumpla la convergencia. Primero hallamos la función característica de $\bar{X}_n$:
$$\varphi_{\bar{X}_n}(t) = \E( \exp\{ it \bar{X}_n \}) = \E \left( \exp\left\{ it \frac{1}{n} \sum\limits_{j = 1}^{n} X_j \right\} \right) = \left[ \E \left( \exp\left\{ \frac{it}{n} X \right\} \right) \right]^n = \left[ \varphi_{X} \big( t/n \big) \right]^n$$

Luego, si la sucesión converge a $\mu$ en distribución, entonces converge a una variable aleatoria con distribución degenerada en $\mu$. Por lo tanto, su función característica estará dada por:
$$\varphi_{X}(t) = \E \big( e^{itX} \big) = e^{it\mu} \, \Pr(X = \mu) + 0 \, \Pr( X \neq \mu) = e^{it\mu}$$

Para evaluar el límite cunado $n \rightarrow +\infty$ de $\left[ \varphi_{X} \big( t/n \big) \right]^n$ utilizamos un desarrollo de Taylor en torno a $t = 0$. Dado que por hipótesis sabemos que la variable tiene primer momento finito, sabemos que es diferenciable al menos una vez, por lo tanto, nuestro desarrollo será de primer orden:
$$\begin{array}{rcl}
\lim\limits_{n \rightarrow +\infty} \left[ \varphi_{X} \big( t/n \big) \right]^n & = & \lim\limits_{n \rightarrow +\infty} \left[ \varphi_X(0) + \varphi'_X(0) \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right]^n \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \left[ 1 + i \mu \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right]^n \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \exp\left\{ n \log \left[ 1 + i \mu \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right] \right\} \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \exp\left\{ n \left( i \mu \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right) \right\} \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \exp\left\{ i \mu t + t \, \varepsilon_1(t_1 / n) \right\} \\ \\
   & = & e^{it\mu}
\end{array}$$

Por lo tanto, hemos probado que $\varphi_{\bar{X}_n}(t) \overset{n}{\rightarrow} \varphi_X(t)$ lo cual implíca que $\bar{X}_n \overset{d}{\rightarrow} X$ donde $X$ es tal que $\Pr( X = \mu) = 1$. Por lo tanto, $\bar{X}_n \overset{p}{\rightarrow} \mu$.

# Ejercicio 3

## Parte a: utilizando funciones características

Primero calculamos la función característica de una variable aleatoria con distribución Gamma.
$$\varphi_{Z_n}(t) = \E \big( e^{itz_n} \big) = \int\limits_{\mathbb{R}^+} e^{itz_n} f_{Z_n}(z_n) dz_n = \int\limits_{\mathbb{R}^+} e^{itz_n} \frac{\lambda^n}{\Gamma(n)} e^{-\lambda z_n} z_n^{n - 1} dz_n =$$
$$= \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} \exp\big\{ itz_n -\lambda z_n \big\} z_n^{n - 1} dz_n = \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} \exp\big\{ -( \lambda - it) z_n \big\} z_n^{n - 1} dz_n $$

Realizamos el siguiente cambio de variable (los límites de integración no cambian):

$$y_n = (\lambda - it) z_n \Rightarrow z_n = \frac{y_n}{\lambda - it}$$
$$\frac{dz_n}{dy_n} = \frac{1}{\lambda - it} \Rightarrow dz_n = \frac{dy_n}{\lambda - it}$$

Obtenemos entonces:
$$ \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} \exp\big\{ -( \lambda - it) z_n \big\} z_n^{n - 1} dz_n =  \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} e^{ -y_n } \left( \frac{y_n}{\lambda - it} \right)^{n - 1} \frac{dy_n}{\lambda - it} =$$
$$= \frac{\lambda^n}{(\lambda - it)^n \Gamma(n)} \int\limits_{\mathbb{R}^+} e^{ -y_n } y_n^{n - 1} dy_n = \frac{\lambda^n}{(\lambda - it)^n \Gamma(n)} \int\limits_{\mathbb{R}^+} e^{ -y_n } y_n^{n - 1} \frac{\Gamma(n)}{\Gamma(n)} dy_n =$$
$$= \frac{\lambda^n}{(\lambda - it)^n} \underbrace{ \int\limits_{\mathbb{R}^+} e^{ -y_n } y_n^{n - 1} \frac{1}{\Gamma(n)} dy_n }_{ Y_n \sim \Gamma(1, n) } = \frac{\lambda^n}{(\lambda - it)^n} = \left( \frac{\lambda}{\lambda - it}\right)^n =$$
$$= \left( \frac{\lambda - it}{\lambda}\right)^{-n} = \left( 1 - \frac{it}{\lambda}\right)^{-n}$$

Luego, calculamos el límite buscado.
$$\lim\limits_{n \rightarrow +\infty} \varphi_{Y_n}(t) = \lim\limits_{n \rightarrow +\infty} \varphi_{ \frac{\lambda Z_n}{\sqrt{n}} - \sqrt{n} } (t) = \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \varphi_{Z_n} \left( ^{t \lambda} \!/ \!_{\sqrt{n}} \right) =$$
$$= \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \varphi_{Z_n} \left( ^{t \lambda} \!/ \!_{\sqrt{n}} \right) = \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \, \left(  1 - \frac{ ^{t \lambda} \!/ \!_{\sqrt{n}}}{\lambda} \right)^{-n} = \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \, \left(  1 - \frac{ it }{ \sqrt{n} } \right)^{-n} =$$
$$= \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \, \left(  1 - \frac{ it }{ \sqrt{n} } \right)^{-n} = \lim\limits_{n \rightarrow +\infty} \exp\left\{ -n \log \left( 1 - \frac{ it }{ \sqrt{n} } \right) - it \sqrt{n} \right\} =$$
$$= \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \log \left( 1 - \frac{ it }{ \sqrt{n} } \right) + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \log \left( 1 + \frac{ -it }{ \sqrt{n} } \right) + it \sqrt{n} \right] \right\} =$$
$$= \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \left( \frac{-it}{\sqrt{n}} - \frac{ (^{-it} \!/ \!_{\sqrt{n}})^2 }{2} \right) + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \left( \frac{-it}{\sqrt{n}} - \frac{ (it)^2 }{2n} \right) + it \sqrt{n} \right] \right\} =$$
$$= \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ - it \sqrt{n} + \frac{ t^2 }{2} + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \frac{ t^2 }{2} \right\} = e^{-t^2 / 2}$$

Por lo tanto, $Y_n \overset{d}{\rightarrow} Y \sim \text{N}(0, 1)$.

## Parte b: utilizando el Teorema del Límite Central

Sea laa sucesión de variables aleatorias $\{X_n\}_{n \geq 1}$ iid donde $X_1 \sim \text{Exp}(\lambda)$. Luego, entonces $\E(X_1) = \lambda^{-1}$, $\V(X_1) = \lambda^{-2}$, y $Z_n = \sum\limits_{j = 1}^{n} X_j \sim \Gamma(n, \, \lambda)$. Luego, si aplicamos el Teoremal del Límite Central de Levy, obtenemos que:
$$\frac{ \sum\limits_{j = 1}^{n} X_j - n \E(X_1)}{ \sqrt{n \V(X_1)} } = \frac{Z_n - n \E(X_1)}{ \sqrt{n \V(X_1)} } = \frac{Z_n - n (1 / \lambda)}{ \sqrt{n (1 / \lambda^2) } } = \frac{Z_n - n / \lambda }{ \sqrt{n} / \lambda } =$$
$$= \frac{ \lambda Z_n - n }{ \sqrt{n} } = \frac{ \lambda Z_n }{ \sqrt{n} } - \sqrt{n} = Y_n \overset{d}{\rightarrow} Y \sim \text{N}(0, 1)$$


# Ejercicio 4



# Ejercicio 5



# Ejercicio 6



# Ejercicio 7



# Ejercicio 8



# Ejercicio 9



# Ejercicio 10



# Ejercicio 11



# Ejercicio 12



# Ejercicio 13



# Ejercicio 14


