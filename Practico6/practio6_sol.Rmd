---
title: "Práctico 6"
author: "Daniel Czarnievicz"
date: "2019"
output: pdf_document
header-includes:
   - \everymath{\displaystyle}
   - \usepackage[spanish]{babel}
   - \usepackage{xcolor}
   - \usepackage[makeroom]{cancel}
   - \DeclareMathOperator*{\plim}{plim}
   - \usepackage{mathrsfs}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \usepackage{MnSymbol}
   - \newcommand{\equalexpl}[1]{\underset{\substack{\uparrow\\\\\mathrlap{\text{\hspace{-2em}#1}}}}{\approx}}
   - \DeclareMathOperator{\E}{\mathbf{E}}
   - \DeclareMathOperator{\V}{\mathbf{V}}
   - \usepackage[inline]{enumitem}
geometry: margin=1in
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejercicio 1

Sean las variables aleatorias $A_i =$ "sale 6 en la $i$-ésima tirada", y $A = \sum\limits_{i = 1}^{n} A_i =$ "cantidad de veces que sale 6". Entonces $A_i \sim \text{Ber}(1/6)$, mientras que $A \sim \text{Bin}(180, \, 1/6)$. Luego entonces:

$$\Pr ( \text{``sale 6 menos de 25 veces''} ) = \Pr ( A \leq 24 ) = \Pr \left( \frac{ \sum\limits_{i = 1}^{180} A_i - np }{ \sigma \sqrt{n} } \leq \frac{ 24 - np }{ \sigma \sqrt{n} } \right) =$$
$$= \Pr \left( \frac{ \sum\limits_{i = 1}^{180} A_i - 180 \, (1/6) }{ \sqrt{ (1/6) (5/6) } \, \sqrt{180} } \leq \frac{ 24 - 180 \, (1/6) }{ \sqrt{ (1/6) (5/6) } \, \sqrt{180} } \right) = \Pr \left( Z \leq \frac{ 24 - 30 }{ 30 \sqrt{5} } \right)$$

```{r, comment=""}
n <- 180
p <- 1 / 6
mu <- (n * p)
sigma <- sqrt(p * (1 - p))
x <- 24
pnorm((x - mu) / (sigma * sqrt(n)), mean = 0, sd = 1)
pbinom(x, size = n, prob = p)
sum(dbinom(1:x, size = n, prob = p))
```

\newpage

# Ejercicio 2: LDGN de Khinchin

Probar que si $\{X_n\}_{n \geq 1}$ es una sucesión de variables aleatorias iid con $\E(X_1) = \mu$, entonces $\bar{X}_n \overset{p}{\rightarrow} \mu$.

*Dem*: por el teorema de Slutsky sabemos que si una sucesión de variables aleatorias converge en distribución a una constante, entonces también converge en probabilidad a dicha constante. A su vez, por el teorema 3.11 sabemos que la convergencia de funciones características equivale a la convergencia en distribución. Por lo tanto, debemos obtener las funciones características de $\{X_n\}_{n \geq 1}$ y de $\bar{X}_n$, y verificar que se cumpla la convergencia. Primero hallamos la función característica de $\bar{X}_n$:
$$\varphi_{\bar{X}_n}(t) = \E( \exp\{ it \bar{X}_n \}) = \E \left( \exp\left\{ it \frac{1}{n} \sum\limits_{j = 1}^{n} X_j \right\} \right) = \left[ \E \left( \exp\left\{ \frac{it}{n} X \right\} \right) \right]^n = \left[ \varphi_{X} \big( t/n \big) \right]^n$$

Luego, si la sucesión converge a $\mu$ en distribución, entonces converge a una variable aleatoria con distribución degenerada en $\mu$. Por lo tanto, su función característica estará dada por:
$$\varphi_{X}(t) = \E \big( e^{itX} \big) = e^{it\mu} \, \Pr(X = \mu) + 0 \, \Pr( X \neq \mu) = e^{it\mu}$$

Para evaluar el límite cunado $n \rightarrow +\infty$ de $\left[ \varphi_{X} \big( t/n \big) \right]^n$ utilizamos un desarrollo de Taylor en torno a $t = 0$. Dado que por hipótesis sabemos que la variable tiene primer momento finito, sabemos que es diferenciable al menos una vez, por lo tanto, nuestro desarrollo será de primer orden:
$$\begin{array}{rcl}
\lim\limits_{n \rightarrow +\infty} \left[ \varphi_{X} \big( t/n \big) \right]^n & = & \lim\limits_{n \rightarrow +\infty} \left[ \varphi_X(0) + \varphi'_X(0) \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right]^n \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \left[ 1 + i \mu \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right]^n \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \exp\left\{ n \log \left[ 1 + i \mu \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right] \right\} \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \exp\left\{ n \left( i \mu \frac{t}{n} + \frac{t}{n} \varepsilon_1(t_1 / n) \right) \right\} \\ \\
   & = & \lim\limits_{n \rightarrow +\infty} \exp\left\{ i \mu t + t \, \varepsilon_1(t_1 / n) \right\} \\ \\
   & = & e^{it\mu}
\end{array}$$

Por lo tanto, hemos probado que $\varphi_{\bar{X}_n}(t) \overset{n}{\rightarrow} \varphi_X(t)$ lo cual implíca que $\bar{X}_n \overset{d}{\rightarrow} X$ donde $X$ es tal que $\Pr( X = \mu) = 1$. Por lo tanto, $\bar{X}_n \overset{p}{\rightarrow} \mu$.

# Ejercicio 3

## Parte a: utilizando funciones características

Primero calculamos la función característica de una variable aleatoria con distribución Gamma.
$$\varphi_{Z_n}(t) = \E \big( e^{itz_n} \big) = \int\limits_{\mathbb{R}^+} e^{itz_n} f_{Z_n}(z_n) dz_n = \int\limits_{\mathbb{R}^+} e^{itz_n} \frac{\lambda^n}{\Gamma(n)} e^{-\lambda z_n} z_n^{n - 1} dz_n =$$
$$= \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} \exp\big\{ itz_n -\lambda z_n \big\} z_n^{n - 1} dz_n = \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} \exp\big\{ -( \lambda - it) z_n \big\} z_n^{n - 1} dz_n $$

Realizamos el siguiente cambio de variable (los límites de integración no cambian):

$$y_n = (\lambda - it) z_n \Rightarrow z_n = \frac{y_n}{\lambda - it}$$
$$\frac{dz_n}{dy_n} = \frac{1}{\lambda - it} \Rightarrow dz_n = \frac{dy_n}{\lambda - it}$$

Obtenemos entonces:
$$ \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} \exp\big\{ -( \lambda - it) z_n \big\} z_n^{n - 1} dz_n =  \frac{\lambda^n}{\Gamma(n)} \int\limits_{\mathbb{R}^+} e^{ -y_n } \left( \frac{y_n}{\lambda - it} \right)^{n - 1} \frac{dy_n}{\lambda - it} =$$
$$= \frac{\lambda^n}{(\lambda - it)^n \Gamma(n)} \int\limits_{\mathbb{R}^+} e^{ -y_n } y_n^{n - 1} dy_n = \frac{\lambda^n}{(\lambda - it)^n \Gamma(n)} \int\limits_{\mathbb{R}^+} e^{ -y_n } y_n^{n - 1} \frac{\Gamma(n)}{\Gamma(n)} dy_n =$$
$$= \frac{\lambda^n}{(\lambda - it)^n} \underbrace{ \int\limits_{\mathbb{R}^+} e^{ -y_n } y_n^{n - 1} \frac{1}{\Gamma(n)} dy_n }_{ Y_n \sim \Gamma(1, n) } = \frac{\lambda^n}{(\lambda - it)^n} = \left( \frac{\lambda}{\lambda - it}\right)^n =$$
$$= \left( \frac{\lambda - it}{\lambda}\right)^{-n} = \left( 1 - \frac{it}{\lambda}\right)^{-n}$$

Luego, calculamos el límite buscado.
$$\lim\limits_{n \rightarrow +\infty} \varphi_{Y_n}(t) = \lim\limits_{n \rightarrow +\infty} \varphi_{ \frac{\lambda Z_n}{\sqrt{n}} - \sqrt{n} } (t) = \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \varphi_{Z_n} \left( ^{t \lambda} \!/ \!_{\sqrt{n}} \right) =$$
$$= \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \varphi_{Z_n} \left( ^{t \lambda} \!/ \!_{\sqrt{n}} \right) = \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \, \left(  1 - \frac{ ^{t \lambda} \!/ \!_{\sqrt{n}}}{\lambda} \right)^{-n} = \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \, \left(  1 - \frac{ it }{ \sqrt{n} } \right)^{-n} =$$
$$= \lim\limits_{n \rightarrow +\infty} e^{-it\sqrt{n}} \, \left(  1 - \frac{ it }{ \sqrt{n} } \right)^{-n} = \lim\limits_{n \rightarrow +\infty} \exp\left\{ -n \log \left( 1 - \frac{ it }{ \sqrt{n} } \right) - it \sqrt{n} \right\} =$$
$$= \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \log \left( 1 - \frac{ it }{ \sqrt{n} } \right) + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \log \left( 1 + \frac{ -it }{ \sqrt{n} } \right) + it \sqrt{n} \right] \right\} =$$
Utilizamos el siguiente equivalente: $\log(1 + u) \leadsto u - \frac{u^2}{2}$ cuando $u \rightarrow 0$, de donde obtenemos:
$$= \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \left( \frac{-it}{\sqrt{n}} - \frac{ (^{-it} \!/ \!_{\sqrt{n}})^2 }{2} \right) + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ n \left( \frac{-it}{\sqrt{n}} - \frac{ (it)^2 }{2n} \right) + it \sqrt{n} \right] \right\} =$$
$$= \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \left[ - it \sqrt{n} + \frac{ t^2 }{2} + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow +\infty} \frac{ t^2 }{2} \right\} = e^{-t^2 / 2}$$

Por lo tanto, $Y_n \overset{d}{\rightarrow} Y \sim \text{N}(0, 1)$.

## Parte b: utilizando el Teorema del Límite Central

Sea laa sucesión de variables aleatorias $\{X_n\}_{n \geq 1}$ iid donde $X_1 \sim \text{Exp}(\lambda)$. Luego, entonces $\E(X_1) = \lambda^{-1}$, $\V(X_1) = \lambda^{-2}$, y $Z_n = \sum\limits_{j = 1}^{n} X_j \sim \Gamma(n, \, \lambda)$. Luego, si aplicamos el Teoremal del Límite Central de Levy, obtenemos que:
$$\frac{ \sum\limits_{j = 1}^{n} X_j - n \E(X_1)}{ \sqrt{n \V(X_1)} } = \frac{Z_n - n \E(X_1)}{ \sqrt{n \V(X_1)} } = \frac{Z_n - n (1 / \lambda)}{ \sqrt{n (1 / \lambda^2) } } = \frac{Z_n - n / \lambda }{ \sqrt{n} / \lambda } =$$
$$= \frac{ \lambda Z_n - n }{ \sqrt{n} } = \frac{ \lambda Z_n }{ \sqrt{n} } - \sqrt{n} = Y_n \overset{d}{\rightarrow} Y \sim \text{N}(0, 1)$$

# Ejercicio 4: aproximación Normal de la Poisson

Primero hallamos la función característica de una varaible aleatoria con distribución $\text{Poisson}(\lambda)$:
$$\varphi_{Z_{\lambda}}(t) = \E \big( e^{itz} \big) = \sum\limits_{z = 0}^{+\infty} e^{itz} e^{-\lambda} \frac{\lambda^z}{z!} = e^{-\lambda} \sum\limits_{z = 0}^{+\infty} \frac{ (\lambda e^{it})^z }{ z! } = e^{-\lambda} e^{ \lambda e^{it} } = \exp\left\{ \lambda \big( e^{it} - 1 \big) \right\} $$

Luego calculamos el límite de la función característica de la transformación propuesta cuando $\lambda \rightarrow + \infty$.
$$\lim\limits_{\lambda \rightarrow + \infty} \varphi_{ \frac{ Z_{\lambda} }{ \sqrt{\lambda} } - \sqrt{\lambda} }(t) = \lim\limits_{\lambda \rightarrow + \infty} e^{-it \sqrt{\lambda}} \, \varphi_{ Z_{\lambda} } \left( ^t\! / \!_{\sqrt{\lambda}} \right)  = \lim\limits_{\lambda \rightarrow + \infty} e^{-it \sqrt{\lambda}} \, \exp\left\{ \lambda \big( e^{it / \sqrt{\lambda}} - 1 \big) \right\} =$$
$$ = \lim\limits_{\lambda \rightarrow + \infty} \exp\left\{ \lambda \big( e^{it / \sqrt{\lambda}} - 1 \big) -it \sqrt{\lambda} \right\} = \lim\limits_{\lambda \rightarrow + \infty} \exp\left\{ \lambda \left( e^{it / \sqrt{\lambda}} - 1 - \frac{it}{\sqrt{\lambda}} \right) \right\} =$$
$$= \exp\left\{ \lim\limits_{\lambda \rightarrow + \infty} \lambda \left( e^{it / \sqrt{\lambda}} - 1 - \frac{it}{\sqrt{\lambda}} \right) \right\}$$

\newpage

Utilizamos el siguiente dearrollo de Taylor de orden 2 entorno a $x = 0$.
$$e^{x} = e^{0} +  e^{0} \, \frac{x}{1!} + e^{0} \, \frac{x^2}{2!} + \varepsilon_2(x_1) \frac{x^2}{2!}$$
donde $\varepsilon_2(x_1)$ es tal que $\varepsilon_2(x_1) \rightarrow 0$ cuando $x \rightarrow 0$ con $0 < x_1 < t$. Si $x = it / \sqrt{\lambda}$, obtenemos que:
$$\begin{array}{rcl}
e^{it / \sqrt{\lambda}} & = & 1 + \frac{ it / \sqrt{\lambda} }{1!} + \frac{ (it / \sqrt{\lambda})^2 }{2!} + \varepsilon_2(x_1) \frac{ (it / \sqrt{\lambda})^2 }{2!} \\ \\
   & = & 1 + \frac{ it }{ \sqrt{\lambda} } + \frac{ (it)^2 }{ 2 \lambda } + \frac{ (it)^2 }{ 2 \lambda } \varepsilon_2(x_1) \\ \\
   & = & 1 + \frac{ it }{ \sqrt{\lambda} } - \frac{ t^2 }{ 2 \lambda } - \frac{ t^2 }{ 2 \lambda } \varepsilon_2(x_1)
\end{array}$$

Por lo tanto,
$$\begin{array}{rcl}
\lim\limits_{\lambda \rightarrow + \infty} \varphi_{ \frac{ Z_{\lambda} }{ \sqrt{\lambda} } - \sqrt{\lambda} }(t) & = & \exp\left\{ \lim\limits_{\lambda \rightarrow + \infty} \lambda \left( 1 + \frac{ it }{ \sqrt{\lambda} } - \frac{ t^2 }{ 2 \lambda } - 1 - \frac{it}{\sqrt{\lambda}} \right) \right\} \\ \\
   & = & \exp\left\{ \lim\limits_{\lambda \rightarrow + \infty} \lambda \left( - \frac{ t^2 }{ 2 \lambda } \right) \right\} \\ \\
   & = & \exp\left\{ \lim\limits_{\lambda \rightarrow + \infty} \left( - \frac{ t^2 }{ 2 } \right) \right\} \\ \\
   & = & e^{-t^2 / 2}
\end{array}$$

# Ejercicio 5

## Parte i

Comenzamos utilizando las propiedades de la proposición 3.3, de donde obtenemos que:
$$\varphi_{ \sqrt{n}( \bar{Y}_n - 1) }(t) = e^{-it \sqrt{n}} \varphi_{ \bar{Y}_n }(t \sqrt{n}) = e^{-it \sqrt{n}} \varphi_{ \frac{1}{n} \sum\limits_{j = 0}^{n} Y_j }(t \sqrt{n}) =$$
$$= e^{-it \sqrt{n}} \prod\limits_{j = 0}^{n} \varphi_{ \frac{1}{n} Y_j }(t \sqrt{n}) = e^{-it \sqrt{n}} \prod\limits_{j = 0}^{n} \varphi_{ Y_j }(t / \sqrt{n}) = e^{-it \sqrt{n}} \left[ \varphi_{ Y_1 }(t / \sqrt{n}) \right]^n$$

\newpage

Luego debemos hallamos la función característica de $Y_1 = X_1^2 \sim \chi^2_1$. Pero si $Y_1 \sim \chi^2_1$ entonces $Y_1 \sim \Gamma(1/2, \, 1/2)$, por lo que su función característica será (ver detalles en ejercicio 3):
$$\varphi_{Y_1}(t) = \left( 1 - \frac{it}{^1\!/_2} \right)^{-^1\!/_2} = \left( 1 - 2it \right)^{-^1\!/_2}$$

Por lo tanto, necesitamos estudiar el siguiente límite:
$$\lim\limits_{n \rightarrow + \infty} \varphi_{ \sqrt{n}( \bar{Y}_n - 1) }(t) = \lim\limits_{n \rightarrow + \infty} e^{-it \sqrt{n}} \left( 1 - \frac{2it}{\sqrt{n}} \right)^{-^n\!/_2} = \lim\limits_{n \rightarrow + \infty} e^{-it \sqrt{n}} \exp\left\{ -\frac{n}{2} \log  \left( 1 - \frac{2it}{\sqrt{n}} \right) \right\} =$$
$$= \lim\limits_{n \rightarrow + \infty} \exp\left\{ -\frac{n}{2} \log  \left( 1 - \frac{2it}{\sqrt{n}} \right) - it \sqrt{n} \right\} = \exp\left\{ - \lim\limits_{n \rightarrow + \infty} \left[ \frac{n}{2} \log  \left( 1 + \frac{-2it}{\sqrt{n}} \right) + it \sqrt{n} \right] \right\}$$

A continuación utilizamos la equivalencia $\log(1 + u) \leadsto u - \frac{u^2}{2}$ cuando $u \rightarrow 0$, y obtenemos que:
$$= \exp\left\{ - \lim\limits_{n \rightarrow + \infty} \left[ \frac{n}{2} \left( \frac{-2it}{\sqrt{n}} - \frac{(-2it)^2}{2n} \right) + it \sqrt{n} \right] \right\} = \exp\left\{ - \lim\limits_{n \rightarrow + \infty} \left[ - it \sqrt{n} + t^2 + it \sqrt{n} \right] \right\} = e^{-t^2}$$

Por lo tanto, $\sqrt{n} \big( \bar{Y}_n - 1 \big) \overset{d}{\rightarrow} Z \sim \text{N}(0, \, 2)$.

## Parte ii

Dado el resultado de la parte i, y dado que $f:f(x) = x^r$ es continua y derivable, podemos aplicar el Método Delta. De esta forma, obtenemos que para todo $r > 0$:
$$\sqrt{n} \big( \bar{Y}_n^r - 1 \big) = \sqrt{n} \big( \bar{Y}_n^r - 1^r \big) = \sqrt{n} \big( f(\bar{Y}_n) - f(1) \big) \overset{d}{\rightarrow} W \sim \text{N}\big( 0, \, 2 (f'(1))^2 \big) \overset{d}{=} \text{N}\big( 0, \, V^2(r) \big)$$
donde, dado que $f:f(x) = x^r$, $f':f'(x) = r x^{r-1}$. Por lo tanto, $(f'(1))^2 = r^2$ entonces $V^2(r) = 2r^2$.

## Parte iii

Aplicando el resultado de la parte ii obtenemos que:
$$\frac{ \sqrt{n} \left( \bar{Y}_n^{^1/_3} - \left( 1 - \frac{2}{9n} \right) \right) }{ \sqrt{ ^2\!/_9 } } = \frac{ \sqrt{n} \left( \bar{Y}_n^{^1/_3} - 1 \right) }{ \sqrt{ ^2\!/_9 } } + \frac{ \sqrt{n} \left( ^2 / _{9n} \right) }{ \sqrt{ ^2\!/_9 } } =$$
$$= \underbrace{ \left( \sqrt{ ^9\!/_2 } \right) \overbrace{ \sqrt{n} \left( \bar{Y}_n^{^1/_3} - 1 \right)}^{ \overset{d}{\rightarrow} \text{N}(0, \, ^2\!/_9) }}_{ \overset{d}{\rightarrow} \text{N}(0, \, 1) } + \underbrace{ \sqrt{ ^2 / _{9n} } }_{ \overset{n}{\rightarrow} 0 } \overset{d}{\rightarrow} Z \sim \text{N}(0, \, 1)$$

# Ejercicio 6

Por el Teorema del Límite Central de Levy sabemos que $\big( \sigma^2 n \big)^{-^1/_2} \sum\limits_{j = 1}^{n} X_j \overset{d}{\rightarrow} Z \sim \text{N}(0, \, 1)$, por lo que:
$$\frac{ \bar{X}_n }{ \sigma / \sqrt{n} } \overset{d}{\rightarrow} Z \sim \text{N}(0, \, 1)$$

Luego, sobre el denominador sabemos que:
$$S_n^2 = \frac{1}{n} \sum\limits_{j = 1}^{n} \big( X_j - \bar{X}_n \big)^2 = \frac{1}{n} \sum\limits_{j = 1}^{n} X_j^2 - n \underbrace{ \bar{X}_n^2}_{ \overset{p}{\rightarrow} \mu = 0 } \overset{p}{\rightarrow} \sigma^2$$

Por lo tanto,
$$\frac{1}{n \sigma^2} \sum\limits_{j = 1}^{n} X_j^2 \overset{p}{\rightarrow} 1 \Rightarrow \sqrt{ \frac{1}{n \sigma^2} \sum\limits_{j = 1}^{n} X_j^2 } = \frac{ 1 }{ \sigma \sqrt{n} } \sqrt{ \sum\limits_{j = 1}^{n} X_j^2 } \overset{p}{\rightarrow} \sqrt{1}$$
dado que $f(z) = \sqrt{z}$ es continua en todo su dominio. Luego entonces, por el teorema de Slutsky, tenemos que:
$$\frac{ \sum\limits_{j = 1}^{n} X_j }{ \sqrt{ \sum\limits_{j = 1}^{n} X_j^2 } } = \frac{ \left( \frac{1}{\sigma / \sqrt{n}} \right) \sum\limits_{j = 1}^{n} X_j }{ \left( \frac{1}{\sigma / \sqrt{n}} \right) \sqrt{ \sum\limits_{j = 1}^{n} X_j^2 } } \overset{d}{\rightarrow} Z \sim \text{N}(0, \, 1)$$

\newpage

# Ejercicio 7

**Hipótesis:**

\begin{itemize}
  \item $X_{n1}, \, \ldots, \, X_{nn}$ sucesión de variable aleatorias independientes.
  \item $\E(X_{nk}) = m_{nk}$
  \item $\V(X_{nk}) = \sigma_{nk}^2 < +\infty$
  \item $S_n = \sum\limits_{k = 1}^{n} X_{nk}$
  \item $V_n^2 = \sum\limits_{k = 1}^{n} \sigma^2_{nk}$
\end{itemize}

## Paete a

Demostrar que:
$$\text{Si } \lim\limits_{n \rightarrow + \infty} \frac{1}{V_n^2} \sum\limits_{k = 1}^{n} \E \left[ \big( X_{nk} - m_{nk} \big)^2 \, \mathbb{I}_{ \{ |X_{nk} - m_{nk}| \geq \varepsilon V_n \} } \right] = 0 \Rightarrow \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \{ \sigma^2_{ni} \} \overset{n}{\rightarrow} 0$$

*Dem:*
$$\lim\limits_{n \rightarrow +\infty} \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \{ \sigma^2_{ni} \} = \lim\limits_{n \rightarrow +\infty} \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \left\{ \E \big( X_{nk} - m_{nk} \big)^2 \right\} =$$
$$= \lim\limits_{n \rightarrow +\infty} \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \Big\{ \underbrace{ \E \big( X_{nk} - m_{nk} \big)^2 \mathbb{I}_{ \{ |X_{nk} - m_{nk}| \geq \varepsilon V_n \} } }_{ \overset{n}{\rightarrow} 0 \text{ por hipótesis } } + \E \big( X_{nk} - m_{nk} \big)^2 \mathbb{I}_{ \{ |X_{nk} - m_{nk}| < \varepsilon V_n \} } \Big\} \leq$$
$$\leq \frac{ \delta }{ 2 } + \lim\limits_{n \rightarrow +\infty} \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \left\{ \E \big( X_{nk} - m_{nk} \big)^2 \mathbb{I}_{ \{ |X_{nk} - m_{nk}| < \varepsilon V_n \} } \right\} =$$
$$= \frac{ \delta }{ 2 } + \lim\limits_{n \rightarrow +\infty} \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \Bigg\{ \underbrace{ \E \big( X_{nk} - m_{nk} \big)^2 \mathbb{I}_{ \left\{ \left| \frac{ X_{nk} - m_{nk} }{ V_n } \right| < \varepsilon \right\} } }_{ \leq \varepsilon^2 \text{ por la indicatriz }} \Bigg\} \leq \frac{\delta}{2} + \varepsilon^2 \leq \delta$$

Luego, dado que $\delta$ es arbitrario, eligo $\varepsilon$ tal que $\varepsilon^2 < \frac{\delta}{2}$, y entonces el límite tiende a cero.

## Parte b

Probar que: 
$$\text{Si } \frac{1}{V_n^2} \max\limits_{i = 1, \ldots, n} \{ \sigma^2_{ni} \} \overset{n}{\rightarrow} 0 \Rightarrow \max\limits_{i = 1, \ldots, n} \Big\{ \Pr \big( |X_{nk} - m_{nk}| \geq \varepsilon V_n \big) \Big\} \overset{n}{\rightarrow} 0$$

# Ejercicio 8



# Ejercicio 9



# Ejercicio 10



# Ejercicio 11



# Ejercicio 12



# Ejercicio 13



# Ejercicio 14


